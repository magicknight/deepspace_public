[summary]
    # name of this experiment
    name = 'metrics_dqn'
    author = 'Zhihua Liang'
    discription = 'Defect detection for POL 2020'
[settings]
    # root directory of the project (for saveing logs, models, temp files, etc...)
    project_root = '/home/zhihua/data/work_space'
    # root directory of the dataset
    # dataset_root = '/home/zhihua/data/anomaly/simulation/bunny/bunny_train_on_defect_images'
    # dataset_root = '/home/zhihua/data/anomaly/simulation/bunny/large_defect_bunny_train_on_defect_images'
    dataset_root = '/home/zhihua/data/anomaly/simulation/bunny/metrics_dqn'
    # dataset_root = '/home/zhihua/data/anomaly/simulation/bunny/test'
    # CAD object path
    mesh_file_path = '/home/zhihua/data/mesh/common/bunny/bunny_watertight.stl'
    # agent name
    agent = 'deepspace.agents.defect.metrics.GanAgent'
    # which device to use, can be 'gpu', 'tpu', or 'cpu'
    device = 'gpu'
    # retry times to break the object
    gpu_device = 0
    # if async loading into cuda memory
    async_loading = true    
    # angle range
    batch_size = 8
    # random seed
    seed = 999
    # model parameters
    number_of_layers = 8
    # Learning rate, can be a float number like 0.001 or a list, like [0.1, 0.001, 1e-6]
    learning_rate = 1e-4
    # betas for Adam optimizer
    betas = [0.9, 0.999]
    # eps for Adam optimizer
    eps = 1e-8
    # momentum for Adam optimizer
    momentum = 0.99
    # weight decay
    weight_decay = 1e-5
    # gan model parameters
    num_filt_g = 64
    num_filt_d = 64
    relu_slope = 0.2
    latent_space_size = 1024
    # max epoches to for training.
    max_epoch = 300
    # validate every x epoches
    validate_step = 2
    # save model every x steps
    save_model_step = 2
    # checkpoint file name
    checkpoint_file = 'checkpoint.pth.tar'
    # dataloader name
    data_loader = 'defect_image_dataloader'
    # workers for dataloader
    data_loader_workers = 8
    # data resolution
    image_resolution = [512, 512]
    # channels
    image_channels = 1
    # output format; png or tif
    data_format = 'png'
    # data mode, 'image', 'numpy', 'tfrecord'... or anything when there exist corresponding dataloader
    data_mode = 'image'
    # mode = 'train', 'test', 'validate', 'metrics'
    # mode = 'train'
    # mode = 'test'
    mode = 'metrics'
    # save ouput on first n images during validation, should be smaller than batch size
    save_images = [0, 10]
    # image loss weight
    image_loss_weight = 0.999
    # defect detection threshold, image threshold is the range of the image and area threshold is the cut on area of defect 
    image_threshold = [0.2, 0.8]
    area_threshold = 500
    # noise level for metrics
    gaussian_noise = false
    gaussian_mean = 0
    gaussian_std = 0.0




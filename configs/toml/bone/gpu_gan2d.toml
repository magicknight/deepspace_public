[summary]
    # name of this experiment
    name = 'gpu_gan2dn'
    author = 'Zhihua Liang'
    discription = 'Bone reconstruction on GPU'
    # root directory of the project (for saveing logs, models, temp files, etc...)
    project_root = '/home/zhihua/data/work_space/bone'    
[deepspace]
    ########### agent ###########
    # agent name
    agent = 'deepspace.agents.bone.gpu_gan2d.Agent'
    # which device to use, can be 'gpu', 'tpu', or 'cpu'
    device = 'gpu'
    # which gpu device
    gpu_device = 0
    # random seed
    seed = 999
    # Learning rate, can be a float number like 0.001 or a list, like [0.1, 0.001, 1e-6]
    gen_lr = 1e-1
    dis_lr = 1e-1
    # data augment
    policy = ['color', 'translation', 'cutout']
    # scheduler
    T_0 = 10
    T_mult = 3
    lr_decay = 0.999
    scheduler = 'WarmupAndExponentialDecayScheduler'
    scheduler_divisor = 5
    scheduler_divide_every_n_epochs = 20  
    # image loss and dis loss weight
    loss_weight = 0.99999
    # max epoches to for training.
    max_epoch = 6000
    # mode = 'train', 'test', 'validate'
    mode = 'train'

    ########### dataset ###########
    # dataset name
    train_data = '/home/zhihua/ssd/aligned_LQ.npy'
    target_data = '/home/zhihua/ssd/aligned_HQ.npy'
    valid_data = '/home/zhihua/ssd/valid_LQ.npy'
    valid_target_data = '/home/zhihua/ssd/valid_HQ.npy'
    padding = false
    # load into memory before distributing
    shared_dataset = true    
    # batch
    train_batch = 32
    validate_batch = 8
    # validate length
    validation_size = 256
    # workers for dataloader
    data_loader_workers = 16
    # image size and channel
    image_channels = 1
    image_size = [768, 768]
    # data argument
    drop_probability = [0.05, 0.3]
    break_probability = 0.5
    min_erasing_area = 0.01
    max_erasing_area = 0.1
    min_aspect_ratio = 0.3
    value = 0
    # dataloader options
    drop_last = true
    shuffle = false


    ########## model ############
    # validate every x epoches
    validate_step = 10    
    # save model every x steps
    save_model_step = 10
    backup_model_step = 30    
    # save ouput on first n images during validation
    save_images = [0, 3]
    save_image_step = 10
    # checkpoint file name
    checkpoint_file = 'checkpoint.pth.tar'
    # generator model
    gen_encoder_sizes = [8, 12, 32, 48, 64, 96, 128, 192]
    gen_temporal_strides = [2, 2, 2, 2, 2, 2, 2, 2]
    gen_fc_sizes = [1536]
    # discriminator model
    dis_encoder_sizes = [8, 12, 32, 48, 64, 96, 128, 192]
    dis_temporal_strides = [2, 2, 2, 2, 2, 2, 2, 2]
    dis_fc_sizes = [16, 1]
    # output format; png or tif
    data_format = 'npy'

    

    ##### test ######
    test_dataset = '/home/zhihua/ssd/npy/aligned_LQ.npy'
    test_batch = 16
    test_output_dir = '/home/zhihua/data/work_space/bone/aligned_gan3d_test'

[common]
    distribute = false
    # log level, can be INFO, WARNING, ERROR..., see python logging
    log_level = 'INFO'

